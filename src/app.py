# app.py
# ------------------------------------------------------------
# Clustering com PyCaret + Streamlit (PyCaret 3.x)
# Base: Iris (ou CSV) | M√©tricas + Interpreta√ß√£o
# Dendrograma (scipy) + Heatmap de m√©dias (plotly)
# Sele√ß√£o de n¬∫ de clusters (k) p/ kmeans/hclust/birch/spectral
# Par√¢metros p/ DBSCAN e OPTICS
# Compat√≠vel com Python 3.9+
# ------------------------------------------------------------
import streamlit as st
import pandas as pd
import numpy as np
from typing import List, Optional
import os

from pycaret.datasets import get_data
from pycaret.clustering import (
    setup, create_model, assign_model, plot_model, save_model
)

from sklearn.metrics import (
    silhouette_score,
    calinski_harabasz_score,
    davies_bouldin_score
)

# Gr√°ficos extras
from scipy.cluster.hierarchy import linkage, dendrogram
import matplotlib.pyplot as plt
import plotly.express as px

st.set_page_config(page_title="Clustering com PyCaret", layout="wide")
st.title("Clusteriza√ß√£o Autom√°tica com PyCaret (v3.x) ‚Äî com Dendrograma e Heatmap")

# Abas principais do corpo do app
tab_orient, tab_eda, tab_treino, tab_relatorio = st.tabs([
    "Orienta√ß√µes",
    "EDA (profiling)",
    "Treino & M√©tricas",
    "Relat√≥rio",
])

# Containers para facilitar roteamento de conte√∫do
orient_container = tab_orient.container()
eda_container = tab_eda.container()
treino_container = tab_treino.container()
relatorio_container = tab_relatorio.container()

# ============================================================
# Aba Orienta√ß√µes
# ============================================================
with orient_container:
    st.subheader("Orienta√ß√µes de Uso ‚Äî Clustering com PyCaret")

    st.markdown("""
        ### **1. Objetivo do Aplicativo**

        Este aplicativo tem como objetivo **descobrir padr√µes ocultos em bases de dados num√©ricos** atrav√©s de **algoritmos de aprendizado n√£o supervisionado (clustering)**.  
        Ele utiliza a biblioteca **PyCaret**, permitindo explorar, treinar e interpretar modelos sem necessidade de programa√ß√£o manual.

        O app foi projetado para:
        - Facilitar **an√°lises explorat√≥rias (EDA)**;  
        - Realizar **pr√©-processamento autom√°tico** (normaliza√ß√£o, PCA, sele√ß√£o de colunas);  
        - Treinar e comparar **m√∫ltiplos algoritmos de clusteriza√ß√£o**;  
        - Exibir **m√©tricas e visualiza√ß√µes** de qualidade dos clusters;  
        - Permitir **interpreta√ß√£o dos resultados** e **download** do modelo e dos dados rotulados.
        
        ---

        ### **2. Escolha e Carregamento do Dataset**

        Na **barra lateral (Sidebar)**, voc√™ encontrar√° a se√ß√£o **‚ÄúFonte de Dados‚Äù** com duas op√ß√µes:

        #### **Op√ß√£o 1 ‚Äî Iris (Exemplo)**
        - Dataset cl√°ssico de classifica√ß√£o com 3 classes (`setosa`, `versicolor`, `virginica`).
        - Serve para **testes r√°pidos** e valida√ß√£o do funcionamento do app.
        - √â carregado automaticamente pelo PyCaret (`get_data("iris")`).

        #### **Op√ß√£o 2 ‚Äî Upload CSV (Seu Dataset)**
        - Utilize esta op√ß√£o para enviar seu pr√≥prio arquivo `.csv`.
        - No contexto deste projeto, use o arquivo **`Country-data.csv`**, que cont√©m dados socioecon√¥micos de 167 pa√≠ses.

        > ‚ö†Ô∏è **Importante:**  
        > - O dataset `Country-data.csv` inclui uma coluna chamada `country`, que **identifica os pa√≠ses**.  
        > - Essa coluna **n√£o deve ser usada no treinamento**, pois n√£o √© num√©rica.  
        > - Na barra lateral, em **Configura√ß√£o das Features**, use o campo **‚ÄúSelecione features para ignorar‚Äù** para marcar `country` (pr√©-selecionada por padr√£o).  
        > - As colunas escolhidas nesse campo ser√£o ignoradas pelo `setup` do PyCaret.
        
        ---

        ### **3. Configura√ß√£o das Features**

        Ap√≥s carregar o dataset:
        - Primeiro, use o campo **‚ÄúSelecione features para ignorar‚Äù** para excluir colunas do treinamento (ex.: `country`). Por padr√£o, `country` j√° vem pr√©-selecionada.  
        - As colunas num√©ricas s√£o detectadas automaticamente.  
        - Voc√™ pode selecionar manualmente quais features usar (menu **‚ÄúSelecione features num√©ricas‚Äù**).  

        Para o `Country-data.csv`, recomenda-se incluir:
        child_mort, exports, health, imports, income, inflation, life_expec, total_fer, gdpp

        Essas vari√°veis descrevem **aspectos econ√¥micos e sociais** de cada pa√≠s e servir√£o de base para a descoberta dos grupos.
        
        ---

        ### **4. Pr√©-Processamento**

        A se√ß√£o **‚ÄúPr√©-processamento‚Äù** permite ajustar o comportamento dos dados antes do clustering:

        | Op√ß√£o | Fun√ß√£o | Recomenda√ß√£o |
        |-------|--------|---------------|
        | **Normalizar** | Padroniza todas as vari√°veis (m√©dia=0, desvio=1). | ‚úÖ **Ativar sempre** (algoritmos de clustering s√£o sens√≠veis √† escala). |
        | **Aplicar PCA** | Reduz dimensionalidade via An√°lise de Componentes Principais. | ‚ùå **Desativar** para `Country-data.csv` (mant√©m interpretabilidade). |
        | **Componentes PCA** | Define o n√∫mero de componentes a reter. | Usado apenas se PCA estiver ativado. |

        > üîé *Dica:* A normaliza√ß√£o garante que vari√°veis como ‚Äúincome‚Äù (valores grandes) e ‚Äúhealth‚Äù (% do PIB) contribuam igualmente no agrupamento.
        
        ---

        ### **5. Par√¢metros de Clusteriza√ß√£o**

        A pr√≥xima se√ß√£o da barra lateral define **par√¢metros espec√≠ficos dos algoritmos**:

        | Par√¢metro | Descri√ß√£o | Recomenda√ß√µes |
        |------------|------------|---------------|
        | **N√∫mero de clusters (k)** | Usado em *K-Means*, *Hierarchical Clustering*, *Birch*, *Spectral*. | Se `0`, o app escolher√° automaticamente (usando o gr√°fico de cotovelo). |
        | **DBSCAN ‚Äì eps** | Dist√¢ncia m√°xima entre pontos para formar um cluster. | Para `Country-data.csv`, experimente valores entre `0.5` e `1.5`. |
        | **DBSCAN ‚Äì min_samples** | N√∫mero m√≠nimo de pontos por cluster. | Valores entre `3` e `10` geralmente funcionam bem. |
        | **OPTICS ‚Äì min_samples** | Par√¢metro an√°logo ao DBSCAN. | Pode deixar o padr√£o (`5`). |
        
        ---

        ### **6. Execu√ß√£o do Treinamento**

        Na aba **‚ÄúTreino & M√©tricas‚Äù**, clique em **‚ÄúRodar Clusteriza√ß√£o‚Äù**.  
        O app ir√°:

        1. Aplicar o pr√©-processamento configurado (normaliza√ß√£o e PCA se marcado);  
        2. Treinar todos os algoritmos selecionados na barra lateral;  
        3. Calcular automaticamente as m√©tricas de qualidade:
        - **Silhouette Score** ‚Üí quanto maior, melhor separa√ß√£o;
        - **Calinski‚ÄìHarabasz Index** ‚Üí quanto maior, melhor;
        - **Davies‚ÄìBouldin Index** ‚Üí quanto menor, melhor;
        4. Exibir uma **tabela comparativa** com os resultados e uma **interpreta√ß√£o autom√°tica** das m√©tricas.
        
        ---

        ### **7. Interpreta√ß√£o e Visualiza√ß√£o dos Clusters**

        Ap√≥s o treinamento:
        - Escolha um modelo espec√≠fico (ex.: *kmeans*, *hclust*, *dbscan*) para an√°lise detalhada.  
        - S√£o exibidos:
        - Tabela com **estat√≠sticas m√©dias por cluster** (perfil socioecon√¥mico de cada grupo);
        - **Gr√°ficos autom√°ticos do PyCaret**:
            - *Elbow Plot*: sugere o n√∫mero ideal de clusters;
            - *Silhouette Plot*: avalia separa√ß√£o dos grupos;
            - *t-SNE Plot*: representa√ß√£o 2D dos clusters;
        - **Dendrograma** (para *Hierarchical Clustering*);
        - **Heatmap interativo** mostrando m√©dias normalizadas por cluster.
        
        ---

        ### **8. Exporta√ß√£o dos Resultados**

        Na parte inferior da aba de treino:
        - Fa√ßa o **download do CSV** com os pa√≠ses e seus respectivos clusters atribu√≠dos;  
        - Baixe o **modelo treinado (.pkl)**, que pode ser reutilizado para novas predi√ß√µes ou deploy.

        A aba **‚ÄúExportar Relat√≥rio‚Äù** apenas centraliza as op√ß√µes de download dispon√≠veis ap√≥s o treino.
        
        ---

        ### **9. Interpreta√ß√£o no Contexto do Country-data.csv**

        Os grupos (clusters) gerados representam **conjuntos de pa√≠ses com caracter√≠sticas socioecon√¥micas semelhantes**.  
        Exemplo de poss√≠veis interpreta√ß√µes:

        - **Cluster 0:** pa√≠ses com alta mortalidade infantil, baixa renda e baixa expectativa de vida;  
        - **Cluster 1:** pa√≠ses de alta renda e boa expectativa de vida;  
        - **Cluster 2:** economias emergentes intermedi√°rias.  

        Esses insights podem ser usados para **an√°lises comparativas**, **planejamento de pol√≠ticas p√∫blicas** ou **estudos de desenvolvimento econ√¥mico**.
        
        ---

        ### **10. Dicas Finais**

        - Use o bot√£o **‚ÄúGerar relat√≥rio (profiling)‚Äù** na aba *EDA* para obter um resumo completo das vari√°veis.  
        - Ajuste o valor de **k** e repita o treinamento para observar mudan√ßas nos agrupamentos.  
        - Compare diferentes algoritmos ‚Äî o **K-Means** costuma gerar resultados mais est√°veis para este dataset.  
        - Evite ativar PCA se o foco for **interpreta√ß√£o das vari√°veis originais**.
    """)

# ============================================================
# Utilidades
# ============================================================
def safe_numeric_df(df: pd.DataFrame, cols: Optional[List[str]]) -> pd.DataFrame:
    """Seleciona apenas colunas num√©ricas (ou as informadas) e remove constantes."""
    if cols:
        num_df = df[cols].copy()
    else:
        num_df = df.select_dtypes(include="number").copy()
    nunique = num_df.nunique(dropna=False)
    keep = nunique[nunique > 1].index.tolist()
    return num_df[keep]

def compute_metrics(X: pd.DataFrame, labels: pd.Series) -> tuple:
    """Retorna (silhouette, calinski-harabasz, davies-bouldin) ou NaN se n√£o houver >1 cluster."""
    if len(np.unique(labels)) <= 1:
        return (np.nan, np.nan, np.nan)
    sil = silhouette_score(X, labels)
    ch = calinski_harabasz_score(X, labels)
    db = davies_bouldin_score(X, labels)
    return (sil, ch, db)

def interpret_row(model_name: str, sil: float, ch: float, db: float) -> str:
    if np.isnan(sil):
        return f"{model_name}: n√£o conseguiu formar m√∫ltiplos clusters ou falhou na avalia√ß√£o."
    parts = []
    if sil > 0.5:
        parts.append(f"Silhouette = {sil:.2f} (boa separa√ß√£o)")
    elif sil > 0.25:
        parts.append(f"Silhouette = {sil:.2f} (moderada, pode melhorar)")
    else:
        parts.append(f"Silhouette = {sil:.2f} (clusters fracos/ru√≠do)")
    parts.append(f"CH = {ch:.1f} (quanto maior, melhor)")
    if db < 0.5:
        parts.append(f"DB = {db:.2f} (excelente compacta√ß√£o)")
    elif db < 1.0:
        parts.append(f"DB = {db:.2f} (bom resultado)")
    else:
        parts.append(f"DB = {db:.2f} (sobreposi√ß√£o entre clusters)")
    return f"{model_name} ‚Üí " + "; ".join(parts) + "."

def cluster_profiles_table(labeled: pd.DataFrame, cluster_col: str = "Cluster") -> pd.DataFrame:
    """Estat√≠sticas descritivas por cluster (mean/median/std/min/max) das vari√°veis num√©ricas."""
    num_cols = labeled.select_dtypes(include="number").columns.tolist()
    num_cols = [c for c in num_cols if c != cluster_col]
    if not num_cols:
        return pd.DataFrame()
    prof = labeled.groupby(cluster_col)[num_cols].agg(["mean", "median", "std", "min", "max"])
    return prof

def best_cluster_label_mapping(labeled: pd.DataFrame, cluster_col="Cluster", truth_col="species") -> tuple:
    """Mapeia cluster -> r√≥tulo mais frequente e calcula pureza (acertos por modo / total)."""
    mapping = {}
    total = len(labeled)
    correct = 0
    for c, group in labeled.groupby(cluster_col):
        mode_label = group[truth_col].mode(dropna=False)
        if len(mode_label) > 0:
            chosen = mode_label.iloc[0]
            mapping[c] = chosen
            correct += (group[truth_col] == chosen).sum()
        else:
            mapping[c] = None
    purity = correct / total if total > 0 else np.nan
    return mapping, purity

def make_dendrogram(X: pd.DataFrame, sample_cap: int = 250, method: str = "ward"):
    """Dendrograma usando scipy; amostra linhas para desempenho."""
    if len(X) > sample_cap:
        X_plot = X.sample(n=sample_cap, random_state=42)
        st.caption(f"Dendrograma com amostra de {sample_cap} linhas (de {len(X)}) para desempenho.")
    else:
        X_plot = X
    Z = linkage(X_plot.values, method=method)
    fig, ax = plt.subplots(figsize=(10, 4))
    dendrogram(Z, truncate_mode="level", p=5, no_labels=True, color_threshold=None, ax=ax)
    ax.set_title(f"Dendrograma (m√©todo: {method})")
    ax.set_ylabel("Dist√¢ncia de liga√ß√£o")
    st.pyplot(fig)

def plot_cluster_means_heatmap(labeled: pd.DataFrame, cluster_col: str = "Cluster",
                               zscore: bool = True, top_n_features: Optional[int] = None):
    """Heatmap das m√©dias por cluster; pode aplicar z-score e limitar √†s top-N features."""
    num_cols = labeled.select_dtypes(include="number").columns.tolist()
    num_cols = [c for c in num_cols if c != cluster_col]
    if not num_cols:
        st.info("Sem colunas num√©ricas para heatmap.")
        return

    means = labeled.groupby(cluster_col)[num_cols].mean()

    # Selecionar features mais discriminativas
    if top_n_features is not None and top_n_features > 0 and top_n_features < len(num_cols):
        var_between = means.var(axis=0)
        selected = var_between.sort_values(ascending=False).head(top_n_features).index
        means = means[selected]

    data_plot = means.copy()
    title_suffix = ""
    if zscore:
        data_plot = (means - means.mean(axis=0)) / (means.std(axis=0).replace(0, np.nan))
        title_suffix = " (z-score)"
        data_plot = data_plot.fillna(0.0)

    # R√≥tulos do eixo Y (evita tentar int() em strings)
    def _fmt_cluster_label(v):
        if isinstance(v, (int, np.integer)):
            return f"Cluster {int(v)}"
        if isinstance(v, (float, np.floating)) and float(v).is_integer():
            return f"Cluster {int(v)}"
        s = str(v)
        return s if s.lower().startswith("cluster") else f"{s}"

    y_labels = [_fmt_cluster_label(i) for i in data_plot.index]

    fig = px.imshow(
        data_plot,
        x=[str(c) for c in data_plot.columns],
        y=y_labels,
        color_continuous_midpoint=0.0 if zscore else None,
        aspect="auto",
        labels=dict(color="intensidade")
    )
    fig.update_layout(title=f"Heatmap das m√©dias por cluster{title_suffix}", height=500)
    st.plotly_chart(fig, use_container_width=True)

# ============================================================
# 1) Fonte de Dados
# ============================================================
st.sidebar.header("Fonte de Dados")
fonte = st.sidebar.radio("Selecione a fonte", ["Iris (Exemplo)", "Upload CSV"])

if fonte == "Iris (Exemplo)":
    df = get_data("iris")
    with treino_container:
        st.write("Usando base de exemplo Iris:", df.shape)
        st.dataframe(df.head())
else:
    file = st.sidebar.file_uploader("Carregue seu CSV", type=["csv"])
    if file:
        df = pd.read_csv(file)
        with treino_container:
            st.write("Pr√©via dos dados carregados:")
            st.dataframe(df.head())
    else:
        st.stop()

# ------------------------------------------------------------
# R√≥tulo opcional (clusters √ó r√≥tulos) ‚Äî patch robusto
# ------------------------------------------------------------
raw_cols = list(df.columns)
display_cols = [str(c) for c in raw_cols]
options_display = ["<nenhum>"] + display_cols

candidates_lower = {"species", "label", "target", "classe", "class"}
guess_idx = None
for i, c in enumerate(raw_cols):
    if str(c).lower() in candidates_lower:
        guess_idx = i
        break
default_index = 0 if guess_idx is None else int(1 + guess_idx)

sel_display = st.sidebar.selectbox(
    "Coluna de r√≥tulo (opcional, para compara√ß√£o)",
    options_display,
    index=default_index,
    help="Opcional: selecione a coluna com r√≥tulos verdadeiros para comparar com os clusters. N√£o √© usada no treinamento."
)
label_col = None if sel_display == "<nenhum>" else raw_cols[display_cols.index(sel_display)]

# ============================================================
# 2) Sele√ß√£o de Colunas
# ============================================================
st.sidebar.header("Configura√ß√£o das Features")
cols_ignore_default = ['country'] if 'country' in df.columns else []
cols_ignore = st.sidebar.multiselect(
    "Selecione features para ignorar",
    df.columns.tolist(),
    default=cols_ignore_default,
    help="Colunas que ser√£o explicitamente ignoradas no setup do PyCaret (ex.: 'country')."
)
cols_num = st.sidebar.multiselect(
    "Selecione features num√©ricas",
    df.columns.tolist(),
    help="Escolha as vari√°veis num√©ricas usadas no clustering. Se nenhuma for escolhida, todas as num√©ricas n√£o constantes ser√£o utilizadas."
)
if not cols_num:
    cols_num = df.select_dtypes(include="number").columns.tolist()
    st.sidebar.info("Usando automaticamente colunas num√©ricas n√£o constantes.")

# ============================================================
# 3) Pr√©-processamento
# ============================================================
st.sidebar.header("Pr√©-processamento")
normalize = st.sidebar.checkbox("Normalizar", value=True)
pca = st.sidebar.checkbox("Aplicar PCA", value=False)
pca_comp = st.sidebar.slider(
    "Componentes PCA",
    2,
    10,
    3,
    help="N√∫mero de componentes principais usados para reduzir dimensionalidade antes do clustering. S√≥ √© aplicado se 'Aplicar PCA' estiver marcado.",
    disabled=not pca
)

# ============================================================
# Par√¢metros de modelos (K, eps, etc.)
# ============================================================
st.sidebar.header("Par√¢metros de cluster")
k_clusters = st.sidebar.number_input(
    "N√∫mero de clusters (k) para k-means/hclust/birch/spectral (0 = auto)",
    min_value=0, value=0, step=1
)
dbscan_eps = st.sidebar.slider(
    "DBSCAN eps",
    min_value=0.05,
    max_value=5.0,
    value=1.0,
    step=0.05,
    help="Raio de vizinhan√ßa do DBSCAN. Aumente para formar menos clusters (mais aglomera√ß√£o); diminua para separar mais."
)
dbscan_min_samples = st.sidebar.number_input(
    "DBSCAN min_samples",
    min_value=1,
    value=5,
    step=1,
    help="N√∫mero m√≠nimo de pontos dentro de 'eps' para um ponto ser n√∫cleo. Aumente para clusters mais conservadores (mais ru√≠do)."
)
optics_min_samples = st.sidebar.number_input(
    "OPTICS min_samples",
    min_value=1,
    value=5,
    step=1,
    help="N√∫mero m√≠nimo de pontos para considerar um n√∫cleo no OPTICS. Controla a densidade m√≠nima dos clusters."
)

# Desempenho
st.sidebar.header("Desempenho")
limit_rows = st.sidebar.number_input(
    "Limitar amostras (0 = sem limite)",
    min_value=0,
    value=0,
    step=100,
    help="Subamostra a base para testes r√°pidos. 0 usa todos os registros; >0 sorteia exatamente esse n√∫mero de linhas."
)
models_to_try = st.sidebar.multiselect(
    "Algoritmos a testar",
    ["kmeans", "hclust", "dbscan", "optics", "birch", "spectral"],
    default=["kmeans", "hclust", "dbscan"]
)

# Extras visuais
st.sidebar.header("Exibi√ß√£o avan√ßada")
show_dendro_anyway = st.sidebar.checkbox("Mostrar dendrograma mesmo se n√£o for hclust", value=False)
heatmap_zscore = st.sidebar.checkbox("Heatmap com z-score (recomendado)", value=True)
heatmap_topn = st.sidebar.number_input("Heatmap: limitar √†s top-N vari√°veis (0 = todas)", min_value=0, value=0, step=1)

# ============================================================
# Aba EDA
# ============================================================
with eda_container:
    st.subheader("Vis√£o geral dos dados")
    st.write("Dimens√µes:", df.shape)
    st.dataframe(df.head())
    if (
        fonte != "Iris (Exemplo)"
        and "file" in locals()
        and file is not None
        and str(getattr(file, "name", "")).lower() == "country-data.csv"
    ):
        st.subheader("Entendimento do dataset")
        st.markdown(
            """
            | Coluna       | Descri√ß√£o                                           | Tipo       | Observa√ß√£o                             |
            | ------------ | --------------------------------------------------- | ---------- | ---------------------------------------|
            | `country`    | Nome do pa√≠s                                        | Categ√≥rica | Identificador (ignorado no clustering) |
            | `child_mort` | Taxa de mortalidade infantil (por 1000 nascimentos) | Num√©rica   | Importante indicador social            |
            | `exports`    | Exporta√ß√µes (% do PIB)                              | Num√©rica   | Econ√¥mico                              |
            | `health`     | Gastos com sa√∫de (% do PIB)                         | Num√©rica   | Econ√¥mico/Social                       |
            | `imports`    | Importa√ß√µes (% do PIB)                              | Num√©rica   | Econ√¥mico                              |
            | `income`     | Renda m√©dia per capita                              | Num√©rica   | Econ√¥mico                              |
            | `inflation`  | Taxa de infla√ß√£o (%)                                | Num√©rica   | Econ√¥mico                              |
            | `life_expec` | Expectativa de vida                                 | Num√©rica   | Social                                 |
            | `total_fer`  | Taxa de fertilidade                                 | Num√©rica   | Social                                 |
            | `gdpp`       | PIB per capita                                      | Num√©rica   | Econ√¥mico                              |
            """
        )
    if st.button("üîç Gerar relat√≥rio (profiling)", use_container_width=False):
        Profile = None
        try:
            from ydata_profiling import ProfileReport as Profile  # type: ignore
        except Exception:
            try:
                from pandas_profiling import ProfileReport as Profile  # type: ignore
            except Exception:
                Profile = None
        if Profile is None:
            st.info("Biblioteca de profiling n√£o instalada. Instale 'ydata-profiling' ou 'pandas-profiling' para ativar.")
        else:
            try:
                with st.spinner("Gerando relat√≥rio..."):
                    profile = Profile(df, title="Profiling ‚Äî Dataset", minimal=False)
                    html_str = profile.to_html()
                st.session_state.eda_profile_html = html_str
                st.success("Relat√≥rio gerado!")
            except Exception as e:
                st.error(f"Falha ao gerar o profiling: {e}")

    if st.session_state.get("eda_profile_html"):
        st.components.v1.html(st.session_state.eda_profile_html, height=900, scrolling=True)
        st.download_button(
            "üíæ Baixar relat√≥rio (HTML)",
            data=st.session_state.eda_profile_html.encode("utf-8"),
            file_name="profiling_relatorio.html",
            mime="text/html",
            use_container_width=False
        )
        if st.button("üóëÔ∏è Limpar Relat√≥rio", use_container_width=False, key="btn_clear_eda_report"):
            st.session_state.pop("eda_profile_html", None)
            st.rerun()

# ============================================================
# 4) Rodar Pipeline - Aba Treino & M√©tricas
# ============================================================
with treino_container:
    if st.button("Rodar Clusteriza√ß√£o"):
        data_full = safe_numeric_df(df, cols_num)
        if limit_rows and limit_rows > 0 and limit_rows < len(data_full):
            data = data_full.sample(n=limit_rows, random_state=42).reset_index(drop=True)
        else:
            data = data_full.copy()

        # Aplicar features a ignorar selecionadas pelo usu√°rio, considerando apenas as presentes nos dados do setup
        ignore_cols_effective = [c for c in cols_ignore if c in data.columns]

        setup(
            data=data,
            session_id=42,
            normalize=normalize,
            pca=pca,
            pca_components=pca_comp if pca else None,
            ignore_features=ignore_cols_effective,
            verbose=False,
            html=False,
        )

        st.success("Setup conclu√≠do")
        st.caption("Observa√ß√£o: colunas constantes foram removidas automaticamente antes do setup.")

        # Testar modelos
        resultados, objetos = [], {}
        k_models = {"kmeans", "hclust", "birch", "spectral"}

        for m in models_to_try:
            try:
                params = {}
                # aplica k se informado (>0) e se o modelo aceitar k
                if (k_clusters is not None) and (int(k_clusters) > 0) and (m in k_models):
                    params["num_clusters"] = int(k_clusters)
                # par√¢metros espec√≠ficos
                if m == "dbscan":
                    params["eps"] = float(dbscan_eps)
                    params["min_samples"] = int(dbscan_min_samples)
                if m == "optics":
                    params["min_samples"] = int(optics_min_samples)

                model = create_model(m, **params)
                labeled = assign_model(model, transformation=True)
                X = labeled.drop(columns=["Cluster"])
                y = labeled["Cluster"]

                sil, ch, db = compute_metrics(X, y)
                resultados.append([m, sil, ch, db])
                objetos[m] = (model, labeled)
            except Exception as e:
                resultados.append([m, np.nan, np.nan, np.nan])
                objetos[m] = (str(e), None)

        res_df = pd.DataFrame(resultados, columns=["Modelo", "Silhouette", "Calinski-Harabasz", "Davies-Bouldin"])
        # Persistir resultados para manter ap√≥s reruns
        st.session_state.cluster_results_df = res_df
        st.session_state.cluster_objects = objetos
        st.session_state.cluster_data_full = data_full
        st.session_state.cluster_data_sample = data
        st.session_state.cluster_df = df
        st.session_state.cluster_label_col = label_col
        st.session_state.cluster_setup_params = {
            "normalize": normalize,
            "pca": pca,
            "pca_components": pca_comp if pca else None,
            "ignore_features_user": cols_ignore,
            "ignore_features_effective": ignore_cols_effective,
        }

        st.success("Clusteriza√ß√£o conclu√≠da")
        st.rerun()

    # Renderiza√ß√£o persistente ap√≥s executar clusteriza√ß√£o
    if st.session_state.get("cluster_results_df") is not None:
        res_df = st.session_state.cluster_results_df
        objetos = st.session_state.cluster_objects
        data_full = st.session_state.cluster_data_full
        df = st.session_state.cluster_df
        label_col = st.session_state.cluster_label_col

        st.subheader("Compara√ß√£o de modelos")
        st.dataframe(res_df)

        # Interpreta√ß√£o autom√°tica
        st.subheader("Interpreta√ß√£o autom√°tica das m√©tricas")
        for _, row in res_df.iterrows():
            st.markdown(interpret_row(row["Modelo"], row["Silhouette"], row["Calinski-Harabasz"], row["Davies-Bouldin"]))

        # Escolher modelo
        st.subheader("An√°lise detalhada")
        escolha = st.selectbox("Modelo", res_df["Modelo"].tolist(), key="cluster_model_select")
        obj, labeled_final = objetos.get(escolha, (None, None))

        if isinstance(obj, str) or labeled_final is None:
            st.warning(f"N√£o foi poss√≠vel analisar {escolha}")
            st.stop()

        st.write("Amostra com clusters atribu√≠dos:")
        st.dataframe(labeled_final.head())

        # Perfis por cluster (tabela)
        st.subheader("Perfis dos clusters (estat√≠sticas)")
        prof = cluster_profiles_table(labeled_final, cluster_col="Cluster")
        if not prof.empty:
            st.dataframe(prof)

        # Recriar contexto do PyCaret para permitir plot_model ap√≥s rerun
        try:
            _cfg = st.session_state.get("cluster_setup_params", {})
            _data_for_setup = st.session_state.get(
                "cluster_data_sample",
                labeled_final.drop(columns=["Cluster"], errors="ignore")
            )
            _user_ignore = _cfg.get("ignore_features_user", [])
            _ignore_features = [c for c in _user_ignore if hasattr(_data_for_setup, "columns") and c in _data_for_setup.columns]

            setup(
                data=_data_for_setup,
                session_id=42,
                normalize=_cfg.get("normalize", True),
                pca=_cfg.get("pca", False),
                pca_components=_cfg.get("pca_components"),
                ignore_features=_ignore_features,
                verbose=False,
                html=False,
            )
        except Exception:
            pass

        # Visualiza√ß√µes do modelo escolhido (PyCaret)
        st.subheader("Visualiza√ß√µes do modelo (PyCaret)")
        for plot_type in ["elbow", "silhouette", "tsne"]:
            try:
                st.markdown(f"Plot: {plot_type}")
                plot_model(obj, plot=plot_type, display_format="streamlit")
            except Exception as e:
                st.info(f"{plot_type} n√£o dispon√≠vel para {escolha}: {e}")

        # Dendrograma
        st.subheader("Dendrograma (hier√°rquico)")
        if escolha == "hclust" or show_dendro_anyway:
            X_for_dendro = labeled_final.drop(columns=["Cluster"])
            make_dendrogram(X_for_dendro, sample_cap=250, method="ward")
        else:
            st.info("Dendrograma √© mais apropriado para hclust. Ative a op√ß√£o na barra lateral para for√ßar exibi√ß√£o.")

        # Heatmap das m√©dias
        st.subheader("Heatmap das m√©dias por cluster")
        top_n = int(heatmap_topn) if heatmap_topn and heatmap_topn > 0 else None
        plot_cluster_means_heatmap(labeled_final, cluster_col="Cluster",
                                   zscore=heatmap_zscore, top_n_features=top_n)

        # Compara√ß√£o com r√≥tulos verdadeiros (opcional)
        if ('label_col' in locals()) and label_col and label_col in df.columns:
            st.subheader("Compara√ß√£o clusters √ó r√≥tulos")
            if limit_rows and limit_rows > 0 and limit_rows < len(data_full):
                sampled_idx = data_full.sample(n=limit_rows, random_state=42).index
                truth_series = df.loc[sampled_idx, label_col].reset_index(drop=True)
            else:
                truth_series = df[label_col].reset_index(drop=True)

            if len(truth_series) == len(labeled_final):
                labeled_cmp = labeled_final.copy()
                labeled_cmp[label_col] = truth_series
                ctab = pd.crosstab(labeled_cmp["Cluster"], labeled_cmp[label_col])
                st.dataframe(ctab)
                mapping, purity = best_cluster_label_mapping(labeled_cmp, cluster_col="Cluster", truth_col=label_col)
                st.write("Mapeamento cluster ‚Üí r√≥tulo mais frequente:")
                st.json(mapping)
                st.write(f"Pureza global: {purity:.3f}")
            else:
                st.info("N√£o foi poss√≠vel alinhar r√≥tulos com a amostra usada no clustering.")

        # Downloads
        st.subheader("Downloads")
        st.download_button("Baixar clusters (CSV)", labeled_final.to_csv(index=False).encode("utf-8"), "clusters.csv")
        os.makedirs(os.path.join("results", "models"), exist_ok=True)
        save_model(obj, os.path.join("results", "models", "modelo_cluster"))
        with open(os.path.join("results", "models", "modelo_cluster.pkl"), "rb") as f:
            st.download_button("Baixar modelo (PKL)", f, "modelo_cluster.pkl")

# ============================================================
# Aba Relat√≥rio
# ============================================================
with relatorio_container:
    # ============================
    # üìä RELAT√ìRIO DE RESULTADOS
    # ============================

    st.header("üìä Relat√≥rio de Resultados da Clusteriza√ß√£o")

    st.markdown("""
    Ap√≥s a execu√ß√£o do processo de clusteriza√ß√£o, o modelo **K-Means** foi identificado como o mais adequado
    para o dataset `Country-data.csv`, com base nas m√©tricas internas obtidas:

    - **Silhouette ‚âà 0.29** ‚Üí separa√ß√£o moderada entre clusters (estrutura existente, mas com sobreposi√ß√£o leve);
    - **Calinski‚ÄìHarabasz ‚âà 54.4** ‚Üí boa compacta√ß√£o e separa√ß√£o interna;
    - **Davies‚ÄìBouldin ‚âà 1.0** ‚Üí separa√ß√£o aceit√°vel entre grupos.

    Esses valores indicam que o K-Means conseguiu capturar **padr√µes socioecon√¥micos distintos entre os pa√≠ses**,
    apesar de transi√ß√µes graduais entre alguns grupos ‚Äî o que √© esperado em dados de desenvolvimento humano e econ√¥mico.
    """)

    # Recuperar dataset rotulado (gerado anteriormente)
    if "labeled_final" in locals() or "labeled_final" in globals():
        labeled = labeled_final.copy()
    else:
        st.warning("Nenhum modelo executado ainda. Execute a clusteriza√ß√£o antes de gerar o relat√≥rio.")
        st.stop()

    # ---------------------------
    # üß≠ Interpreta√ß√£o geral
    # ---------------------------
    st.subheader("üß≠ Interpreta√ß√£o Geral dos Clusters")

    st.markdown("""
    O modelo K-Means formou **4 clusters principais**, que representam **n√≠veis de desenvolvimento econ√¥mico-social** globais.
    Abaixo est√° uma descri√ß√£o geral dos grupos encontrados:

    | Cluster | Descri√ß√£o | Caracter√≠sticas predominantes |
    |----------|------------|-------------------------------|
    | **0** | Pa√≠ses em desenvolvimento intermedi√°rio | Renda e PIB medianos, mortalidade infantil moderada, expectativa de vida m√©dia. |
    | **1** | Pa√≠ses de baixo desenvolvimento | Baixa renda, alta mortalidade infantil, alta fertilidade, baixa expectativa de vida. |
    | **2** | Pa√≠ses desenvolvidos | Alta renda, alta expectativa de vida, baixa mortalidade e fertilidade. |
    | **3** | Outlier(s) de alta renda | Renda e PIB extremamente altos, geralmente um ou poucos pa√≠ses. |

    Esses grupos refletem transi√ß√µes reais entre n√≠veis de desenvolvimento humano observadas globalmente.
    """)

    # ---------------------------
    # üìã Tabela de pa√≠ses e clusters
    # ---------------------------
    st.subheader("üìã Pa√≠ses e seus Clusters")

    st.markdown("""
    A tabela abaixo mostra cada pa√≠s e o grupo (cluster) ao qual foi atribu√≠do.
    Os pa√≠ses est√£o ordenados por cluster para facilitar a interpreta√ß√£o dos agrupamentos.
    """)

    # Garantir coluna 'country' para exibi√ß√£o, mesmo se ignorada no setup
    labeled_display = labeled.copy()
    if 'country' not in labeled_display.columns:
        df_full = st.session_state.get("cluster_df")
        data_full = st.session_state.get("cluster_data_full")
        data_sample = st.session_state.get("cluster_data_sample")
        if df_full is not None and 'country' in df_full.columns:
            if data_sample is not None and data_full is not None and len(data_sample) < len(data_full):
                sampled_idx = data_full.sample(n=len(data_sample), random_state=42).index
                country_series = df_full.loc[sampled_idx, 'country'].reset_index(drop=True)
            else:
                country_series = df_full['country'].reset_index(drop=True)
            if len(country_series) == len(labeled_display):
                labeled_display['country'] = country_series

    cols_to_show = ['Cluster'] + (['country'] if 'country' in labeled_display.columns else [])
    st.dataframe(
        labeled_display[cols_to_show].sort_values(by='Cluster'),
        use_container_width=True,
    )

    # ---------------------------
    # üìä Perfil socioecon√¥mico m√©dio por cluster
    # ---------------------------
    st.subheader("üìä Perfil Socioecon√¥mico M√©dio por Cluster")

    st.markdown("""
    O gr√°fico abaixo apresenta as m√©dias normalizadas das vari√°veis socioecon√¥micas dentro de cada grupo.
    Valores positivos indicam m√©dias **acima da m√©dia global** e negativos, **abaixo da m√©dia global**.
    """)

    # Selecionar apenas colunas num√©ricas
    cols_num = [c for c in labeled_display.columns if c not in ['country', 'Cluster']]
    mean_by_cluster = labeled_display.groupby('Cluster')[cols_num].mean()

    # Gr√°fico de barras comparando perfis m√©dios
    st.bar_chart(mean_by_cluster.T)

    st.caption("""
    **Interpreta√ß√£o:**
    - Clusters com valores positivos em *income* e *gdpp* correspondem a pa√≠ses de alta renda.
    - Clusters com valores negativos em *life_expec* e positivos em *child_mort* refletem menor qualidade de vida.
    - O contraste entre *Cluster 1* (baixo desenvolvimento) e *Cluster 2* (desenvolvidos) √© claro e esperado.
    """)

    # ---------------------------
    # üåç Mapa 2D dos Clusters via PCA
    # ---------------------------
    st.subheader("üåç Visualiza√ß√£o 2D dos Clusters (PCA)")

    st.markdown("""
    O gr√°fico a seguir mostra a separa√ß√£o visual dos pa√≠ses com base em duas componentes principais (**PCA**),
    que resumem a maior parte da variabilidade dos dados originais.
    Pa√≠ses pr√≥ximos possuem caracter√≠sticas socioecon√¥micas semelhantes.
    """)

    from sklearn.decomposition import PCA
    import plotly.express as px

    # Aplicar PCA para reduzir para 2 dimens√µes
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(labeled[cols_num])
    df_pca = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])
    if 'country' in labeled_display.columns:
        df_pca['country'] = labeled_display['country']
    df_pca['Cluster'] = labeled_display['Cluster']

    # Gr√°fico interativo
    hover_col = 'country' if 'country' in df_pca.columns else None
    fig = px.scatter(
        df_pca,
        x='PC1',
        y='PC2',
        color='Cluster',
        hover_name=hover_col,
        title='Mapa Socioecon√¥mico 2D dos Pa√≠ses (Redu√ß√£o PCA)',
    )
    st.plotly_chart(fig, use_container_width=True)

    st.caption("""
    **Leitura do gr√°fico:**
    - Cada ponto representa um pa√≠s, e a cor indica o cluster ao qual pertence.
    - Pa√≠ses pr√≥ximos no espa√ßo bidimensional compartilham indicadores semelhantes.
    - O *Cluster 2* (desenvolvidos) tende a se concentrar em uma regi√£o distinta,
    enquanto *Cluster 1* (baixo desenvolvimento) aparece separado e mais disperso.
    - *Cluster 3* geralmente aparece isolado devido a valores extremos (outliers de alta renda).
    """)

    # ---------------------------
    # üß† Conclus√£o
    # ---------------------------
    st.subheader("üß† Conclus√µes e Pr√≥ximos Passos")

    st.markdown("""
    Com base na an√°lise:

    - O **modelo K-Means com 4 clusters** capturou de forma coerente as diferen√ßas de desenvolvimento entre os pa√≠ses.
    - Os **clusters refletem n√≠veis crescentes de renda, expectativa de vida e qualidade socioecon√¥mica.**
    - A estrutura dos grupos √© **gradual**, indicando que as transi√ß√µes entre n√≠veis de desenvolvimento s√£o cont√≠nuas.

    **Sugest√µes para an√°lises futuras:**
    1. Avaliar *k* diferentes (3 a 5) e comparar a estabilidade dos clusters.  
    2. Incorporar novas vari√°veis (ex.: educa√ß√£o, desigualdade, urbaniza√ß√£o).  
    3. Explorar uma visualiza√ß√£o geogr√°fica (mapa mundial colorido por cluster).  
    4. Aplicar o modelo treinado em anos diferentes para estudar evolu√ß√£o temporal.

    Essas etapas ampliam o entendimento da segmenta√ß√£o global e permitem insights mais profundos sobre os perfis socioecon√¥micos dos pa√≠ses.
    """)
