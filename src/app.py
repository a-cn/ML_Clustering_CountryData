# app.py
# ------------------------------------------------------------
# Clustering com PyCaret + Streamlit (PyCaret 3.x)
# Base: Iris (ou CSV) | M√©tricas + Interpreta√ß√£o
# Dendrograma (scipy) + Heatmap de m√©dias (plotly)
# Sele√ß√£o de n¬∫ de clusters (k) p/ kmeans/hclust/birch/spectral
# Par√¢metros p/ DBSCAN e OPTICS
# Compat√≠vel com Python 3.9+
# ------------------------------------------------------------
import streamlit as st
import pandas as pd
import numpy as np
from typing import List, Optional
import os

from pycaret.datasets import get_data
from pycaret.clustering import (
    setup, create_model, assign_model, plot_model, save_model
)

from sklearn.metrics import (
    silhouette_score,
    calinski_harabasz_score,
    davies_bouldin_score
)

# Gr√°ficos extras
from scipy.cluster.hierarchy import linkage, dendrogram
import matplotlib.pyplot as plt
import plotly.express as px

st.set_page_config(page_title="Clustering com PyCaret", layout="wide")
st.title("Clusteriza√ß√£o Autom√°tica com PyCaret (v3.x)")

# √Çncora e bot√£o flutuante "Topo" dispon√≠vel em todas as abas
st.markdown('<div id="top"></div>', unsafe_allow_html=True)
st.markdown("""
<style>
.back-to-top {
  position: fixed;
  right: 24px;
  bottom: 24px;
  z-index: 9999;
  width: 44px;
  height: 44px;
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  background: var(--primary-color, #2c7be5);
  color: #ffffff !important;
  border: none;
  text-decoration: none !important;
  font-weight: 700;
  font-size: 20px;
  line-height: 1;
  box-shadow: 0 2px 6px rgba(0,0,0,0.2);
}
.back-to-top:visited,
.back-to-top:active,
.back-to-top:focus { color: #ffffff !important; }
.back-to-top:hover { transform: translateY(-2px); opacity: .95; }
@media (prefers-reduced-motion: reduce) { .back-to-top:hover { transform: none; } }
@media (max-width: 600px) { .back-to-top { right: 12px; bottom: 12px; width: 40px; height: 40px; font-size: 18px; } }
</style>
<a href="#top" class="back-to-top" title="Voltar ao topo" aria-label="Voltar ao topo">&#8593;</a>
""", unsafe_allow_html=True)

# Abas principais do corpo do app
tab_orient, tab_eda, tab_treino, tab_relatorio = st.tabs([
    "Orienta√ß√µes",
    "EDA (profiling)",
    "Treino & M√©tricas",
    "Relat√≥rio",
])

# Containers para facilitar roteamento de conte√∫do
orient_container = tab_orient.container()
eda_container = tab_eda.container()
treino_container = tab_treino.container()
relatorio_container = tab_relatorio.container()

# ============================================================
# Aba Orienta√ß√µes
# ============================================================
with orient_container:
    st.subheader("Orienta√ß√µes de Uso ‚Äî Clustering com PyCaret")

    st.markdown("""
        ### **1. Objetivo do Aplicativo**

        Este aplicativo tem como objetivo **descobrir padr√µes ocultos em bases de dados num√©ricos** atrav√©s de **algoritmos de aprendizado n√£o supervisionado (clustering)**.  
        Ele utiliza a biblioteca **PyCaret**, permitindo explorar, treinar e interpretar modelos sem necessidade de programa√ß√£o manual.

        O app foi projetado para:
        - Facilitar **an√°lises explorat√≥rias (EDA)**;  
        - Realizar **pr√©-processamento autom√°tico** (normaliza√ß√£o, PCA, sele√ß√£o de colunas);  
        - Treinar e comparar **m√∫ltiplos algoritmos de clusteriza√ß√£o**;  
        - Exibir **m√©tricas e visualiza√ß√µes** de qualidade dos clusters;  
        - Permitir **interpreta√ß√£o dos resultados** e **download** do modelo e dos dados rotulados.
        
        ---

        ### **2. Escolha e Carregamento do Dataset**

        Na **barra lateral (Sidebar)**, voc√™ encontrar√° a se√ß√£o **‚ÄúFonte de Dados‚Äù** com duas op√ß√µes:

        #### **Op√ß√£o 1 ‚Äî Iris (Exemplo)**
        - Dataset cl√°ssico de classifica√ß√£o com 3 classes (`setosa`, `versicolor`, `virginica`).
        - Serve para **testes r√°pidos** e valida√ß√£o do funcionamento do app.
        - √â carregado automaticamente pelo PyCaret (`get_data("iris")`).

        #### **Op√ß√£o 2 ‚Äî Upload CSV (Seu Dataset)**
        - Utilize esta op√ß√£o para enviar seu pr√≥prio arquivo `.csv`.
        - No contexto deste projeto, use o arquivo **`Country-data.csv`**, que cont√©m dados socioecon√¥micos de 167 pa√≠ses.

        > ‚ö†Ô∏è **Importante:**  
        > - O dataset `Country-data.csv` inclui uma coluna chamada `country`, que **identifica os pa√≠ses**.  
        > - Essa coluna **n√£o deve ser usada no treinamento**, pois n√£o √© num√©rica.  
        > - Na barra lateral, em **Configura√ß√£o das Features**, use o campo **‚ÄúSelecione features para ignorar‚Äù** para marcar `country` (pr√©-selecionada por padr√£o).  
        > - As colunas escolhidas nesse campo ser√£o ignoradas pelo `setup` do PyCaret.
        
        ---

        ### **3. Configura√ß√£o das Features**

        Ap√≥s carregar o dataset:
        - Primeiro, use o campo **‚ÄúSelecione features para ignorar‚Äù** para excluir colunas do treinamento (ex.: `country`). Por padr√£o, `country` j√° vem pr√©-selecionada.  
        - As colunas num√©ricas s√£o detectadas automaticamente.  
        - Voc√™ pode selecionar manualmente quais features usar (menu **‚ÄúSelecione features num√©ricas‚Äù**).  

        Para o `Country-data.csv`, recomenda-se incluir:
        child_mort, exports, health, imports, income, inflation, life_expec, total_fer, gdpp

        Essas vari√°veis descrevem **aspectos econ√¥micos e sociais** de cada pa√≠s e servir√£o de base para a descoberta dos grupos.
        
        ---

        ### **4. Pr√©-Processamento**

        A se√ß√£o **‚ÄúPr√©-processamento‚Äù** permite ajustar o comportamento dos dados antes do clustering:

        | Op√ß√£o | Fun√ß√£o | Recomenda√ß√£o |
        |-------|--------|---------------|
        | **Normalizar** | Padroniza todas as vari√°veis (m√©dia=0, desvio=1). | ‚úÖ **Ativar sempre** (algoritmos de clustering s√£o sens√≠veis √† escala). |
        | **Aplicar PCA** | Reduz dimensionalidade via An√°lise de Componentes Principais. | ‚ùå **Desativar** para `Country-data.csv` (mant√©m interpretabilidade). |
        | **Componentes PCA** | Define o n√∫mero de componentes a reter. | Usado apenas se PCA estiver ativado. |

        > üîé *Dica:* A normaliza√ß√£o garante que vari√°veis como ‚Äúincome‚Äù (valores grandes) e ‚Äúhealth‚Äù (% do PIB) contribuam igualmente no agrupamento.
        
        ---

        ### **5. Par√¢metros de Clusteriza√ß√£o**

        A pr√≥xima se√ß√£o da barra lateral define **par√¢metros espec√≠ficos dos algoritmos**:

        | Par√¢metro | Descri√ß√£o | Recomenda√ß√µes |
        |------------|------------|---------------|
        | **N√∫mero de clusters (k)** | Usado em *K-Means*, *Hierarchical Clustering*, *Birch*, *Spectral*. | Se `0`, o app escolher√° automaticamente (usando o gr√°fico de cotovelo). |
        | **DBSCAN ‚Äì eps** | Dist√¢ncia m√°xima entre pontos para formar um cluster. | Para `Country-data.csv`, experimente valores entre `0.5` e `1.5`. |
        | **DBSCAN ‚Äì min_samples** | N√∫mero m√≠nimo de pontos por cluster. | Valores entre `3` e `10` geralmente funcionam bem. |
        | **OPTICS ‚Äì min_samples** | Par√¢metro an√°logo ao DBSCAN. | Pode deixar o padr√£o (`5`). |
        
        ---

        ### **6. Execu√ß√£o do Treinamento**

        Na aba **‚ÄúTreino & M√©tricas‚Äù**, clique em **‚ÄúRodar Clusteriza√ß√£o‚Äù**.  
        O app ir√°:

        1. Aplicar o pr√©-processamento configurado (normaliza√ß√£o e PCA se marcado);  
        2. Treinar todos os algoritmos selecionados na barra lateral;  
        3. Calcular automaticamente as m√©tricas de qualidade:
        - **Silhouette Score** ‚Üí quanto maior, melhor separa√ß√£o;
        - **Calinski‚ÄìHarabasz Index** ‚Üí quanto maior, melhor;
        - **Davies‚ÄìBouldin Index** ‚Üí quanto menor, melhor;
        4. Exibir uma **tabela comparativa** com os resultados e uma **interpreta√ß√£o autom√°tica** das m√©tricas.
        
        ---

        ### **7. Interpreta√ß√£o e Visualiza√ß√£o dos Clusters**

        Ap√≥s o treinamento:
        - Escolha um modelo espec√≠fico (ex.: *kmeans*, *hclust*, *dbscan*) para an√°lise detalhada.  
        - S√£o exibidos:
        - Tabela com **estat√≠sticas m√©dias por cluster** (perfil socioecon√¥mico de cada grupo);
        - **Gr√°ficos autom√°ticos do PyCaret**:
            - *Elbow Plot*: sugere o n√∫mero ideal de clusters;
            - *Silhouette Plot*: avalia separa√ß√£o dos grupos;
            - *t-SNE Plot*: representa√ß√£o 2D dos clusters;
        - **Dendrograma** (para *Hierarchical Clustering*);
        - **Heatmap interativo** mostrando m√©dias normalizadas por cluster.
        
        ---

        ### **8. Exporta√ß√£o dos Resultados**

        Na parte inferior da aba de treino:
        - Fa√ßa o **download do CSV** com os pa√≠ses e seus respectivos clusters atribu√≠dos;  
        - Baixe o **modelo treinado (.pkl)**, que pode ser reutilizado para novas predi√ß√µes ou deploy.

        A aba **‚ÄúExportar Relat√≥rio‚Äù** apenas centraliza as op√ß√µes de download dispon√≠veis ap√≥s o treino.
        
        ---

        ### **9. Interpreta√ß√£o no Contexto do Country-data.csv**

        Os grupos (clusters) gerados representam **conjuntos de pa√≠ses com caracter√≠sticas socioecon√¥micas semelhantes**.  
        Exemplo de poss√≠veis interpreta√ß√µes:

        - **Cluster 0:** pa√≠ses com alta mortalidade infantil, baixa renda e baixa expectativa de vida;  
        - **Cluster 1:** pa√≠ses de alta renda e boa expectativa de vida;  
        - **Cluster 2:** pa√≠ses de desenvolvimento intermedi√°rio.  

        Esses insights podem ser usados para **an√°lises comparativas**, **planejamento de pol√≠ticas p√∫blicas** ou **estudos de desenvolvimento econ√¥mico**.
        
        ---

        ### **10. Dicas Finais**

        - Use o bot√£o **‚ÄúGerar relat√≥rio (profiling)‚Äù** na aba *EDA* para obter um resumo completo das vari√°veis.  
        - Ajuste o valor de **k** e repita o treinamento para observar mudan√ßas nos agrupamentos.  
        - Compare diferentes algoritmos ‚Äî o **K-Means** costuma gerar resultados mais est√°veis para o dataset `Country-data.csv`.  
        - Evite ativar PCA se o foco for **interpreta√ß√£o das vari√°veis originais**.
    """)

# ============================================================
# Utilidades
# ============================================================
def safe_numeric_df(df: pd.DataFrame, cols: Optional[List[str]]) -> pd.DataFrame:
    """Seleciona apenas colunas num√©ricas (ou as informadas) e remove constantes."""
    if cols:
        num_df = df[cols].copy()
    else:
        num_df = df.select_dtypes(include="number").copy()
    nunique = num_df.nunique(dropna=False)
    keep = nunique[nunique > 1].index.tolist()
    return num_df[keep]

def compute_metrics(X: pd.DataFrame, labels: pd.Series) -> tuple:
    """Retorna (silhouette, calinski-harabasz, davies-bouldin) ou NaN se n√£o houver >1 cluster."""
    if len(np.unique(labels)) <= 1:
        return (np.nan, np.nan, np.nan)
    sil = silhouette_score(X, labels)
    ch = calinski_harabasz_score(X, labels)
    db = davies_bouldin_score(X, labels)
    return (sil, ch, db)

def interpret_row(model_name: str, sil: float, ch: float, db: float) -> str:
    if np.isnan(sil):
        return f"{model_name}: n√£o conseguiu formar m√∫ltiplos clusters ou falhou na avalia√ß√£o."
    parts = []
    if sil > 0.5:
        parts.append(f"Silhouette = {sil:.2f} (boa separa√ß√£o)")
    elif sil > 0.25:
        parts.append(f"Silhouette = {sil:.2f} (moderada, pode melhorar)")
    else:
        parts.append(f"Silhouette = {sil:.2f} (clusters fracos/ru√≠do)")
    parts.append(f"CH = {ch:.1f} (quanto maior, melhor)")
    if db < 0.5:
        parts.append(f"DB = {db:.2f} (excelente compacta√ß√£o)")
    elif db < 1.0:
        parts.append(f"DB = {db:.2f} (bom resultado)")
    else:
        parts.append(f"DB = {db:.2f} (sobreposi√ß√£o entre clusters)")
    return f"{model_name} ‚Üí " + "; ".join(parts) + "."

def cluster_profiles_table(labeled: pd.DataFrame, cluster_col: str = "Cluster") -> pd.DataFrame:
    """Estat√≠sticas descritivas por cluster (mean/median/std/min/max) das vari√°veis num√©ricas."""
    num_cols = labeled.select_dtypes(include="number").columns.tolist()
    num_cols = [c for c in num_cols if c != cluster_col]
    if not num_cols:
        return pd.DataFrame()
    prof = labeled.groupby(cluster_col)[num_cols].agg(["mean", "median", "std", "min", "max"])
    return prof

def best_cluster_label_mapping(labeled: pd.DataFrame, cluster_col="Cluster", truth_col="species") -> tuple:
    """Mapeia cluster -> r√≥tulo mais frequente e calcula pureza (acertos por modo / total)."""
    mapping = {}
    total = len(labeled)
    correct = 0
    for c, group in labeled.groupby(cluster_col):
        mode_label = group[truth_col].mode(dropna=False)
        if len(mode_label) > 0:
            chosen = mode_label.iloc[0]
            mapping[c] = chosen
            correct += (group[truth_col] == chosen).sum()
        else:
            mapping[c] = None
    purity = correct / total if total > 0 else np.nan
    return mapping, purity

def make_dendrogram(X: pd.DataFrame, sample_cap: int = 250, method: str = "ward"):
    """Dendrograma usando scipy; amostra linhas para desempenho."""
    if len(X) > sample_cap:
        X_plot = X.sample(n=sample_cap, random_state=42)
        st.caption(f"Dendrograma com amostra de {sample_cap} linhas (de {len(X)}) para desempenho.")
    else:
        X_plot = X
    Z = linkage(X_plot.values, method=method)
    fig, ax = plt.subplots(figsize=(10, 4))
    dendrogram(Z, truncate_mode="level", p=5, no_labels=True, color_threshold=None, ax=ax)
    ax.set_title(f"Dendrograma (m√©todo: {method})")
    ax.set_ylabel("Dist√¢ncia de liga√ß√£o")
    st.pyplot(fig)

def plot_cluster_means_heatmap(labeled: pd.DataFrame, cluster_col: str = "Cluster",
                               zscore: bool = True, top_n_features: Optional[int] = None):
    """Heatmap das m√©dias por cluster; pode aplicar z-score e limitar √†s top-N features."""
    num_cols = labeled.select_dtypes(include="number").columns.tolist()
    num_cols = [c for c in num_cols if c != cluster_col]
    if not num_cols:
        st.info("Sem colunas num√©ricas para heatmap.")
        return

    means = labeled.groupby(cluster_col)[num_cols].mean()

    # Selecionar features mais discriminativas
    if top_n_features is not None and top_n_features > 0 and top_n_features < len(num_cols):
        var_between = means.var(axis=0)
        selected = var_between.sort_values(ascending=False).head(top_n_features).index
        means = means[selected]

    data_plot = means.copy()
    title_suffix = ""
    if zscore:
        data_plot = (means - means.mean(axis=0)) / (means.std(axis=0).replace(0, np.nan))
        title_suffix = " (z-score)"
        data_plot = data_plot.fillna(0.0)

    # R√≥tulos do eixo Y (evita tentar int() em strings)
    def _fmt_cluster_label(v):
        if isinstance(v, (int, np.integer)):
            return f"Cluster {int(v)}"
        if isinstance(v, (float, np.floating)) and float(v).is_integer():
            return f"Cluster {int(v)}"
        s = str(v)
        return s if s.lower().startswith("cluster") else f"{s}"

    y_labels = [_fmt_cluster_label(i) for i in data_plot.index]

    fig = px.imshow(
        data_plot,
        x=[str(c) for c in data_plot.columns],
        y=y_labels,
        color_continuous_midpoint=0.0 if zscore else None,
        aspect="auto",
        labels=dict(color="intensidade")
    )
    fig.update_layout(title=f"Heatmap das m√©dias por cluster{title_suffix}", height=500)
    st.plotly_chart(fig, use_container_width=True)

# ============================================================
# 1) Fonte de Dados
# ============================================================
st.sidebar.header("Fonte de Dados")
fonte = st.sidebar.radio("Selecione a fonte", ["Iris (Exemplo)", "Upload CSV"])

if fonte == "Iris (Exemplo)":
    df = get_data("iris")
    with treino_container:
        st.write("Usando base de exemplo Iris:", df.shape)
        st.dataframe(df.head())
else:
    file = st.sidebar.file_uploader("Carregue seu CSV", type=["csv"])
    if file:
        df = pd.read_csv(file)
        with treino_container:
            st.subheader("Pr√©via dos dados carregados")
            st.write("Dimens√µes:", df.shape)
            st.dataframe(df.head())
    else:
        st.stop()

# ------------------------------------------------------------
# R√≥tulo opcional (clusters √ó r√≥tulos) ‚Äî patch robusto
# ------------------------------------------------------------
raw_cols = list(df.columns)
display_cols = [str(c) for c in raw_cols]
options_display = ["<nenhum>"] + display_cols

candidates_lower = {"species", "label", "target", "classe", "class"}
guess_idx = None
for i, c in enumerate(raw_cols):
    if str(c).lower() in candidates_lower:
        guess_idx = i
        break
default_index = 0 if guess_idx is None else int(1 + guess_idx)

sel_display = st.sidebar.selectbox(
    "Coluna de r√≥tulo (opcional, para compara√ß√£o)",
    options_display,
    index=default_index,
    help="Opcional: selecione a coluna com r√≥tulos verdadeiros para comparar com os clusters. N√£o √© usada no treinamento."
)
label_col = None if sel_display == "<nenhum>" else raw_cols[display_cols.index(sel_display)]

# ============================================================
# 2) Sele√ß√£o de Colunas
# ============================================================
st.sidebar.header("Configura√ß√£o das Features")
cols_ignore_default = ['country'] if 'country' in df.columns else []
cols_ignore = st.sidebar.multiselect(
    "Selecione features para ignorar",
    df.columns.tolist(),
    default=cols_ignore_default,
    help="Colunas que ser√£o explicitamente ignoradas no setup do PyCaret (ex.: 'country')."
)
cols_num = st.sidebar.multiselect(
    "Selecione features num√©ricas",
    df.columns.tolist(),
    help="Escolha as vari√°veis num√©ricas usadas no clustering. Se nenhuma for escolhida, todas as num√©ricas n√£o constantes ser√£o utilizadas."
)
if not cols_num:
    cols_num = df.select_dtypes(include="number").columns.tolist()
    st.sidebar.info("Usando automaticamente colunas num√©ricas n√£o constantes.")

# ============================================================
# 3) Pr√©-processamento
# ============================================================
st.sidebar.header("Pr√©-processamento")
normalize = st.sidebar.checkbox("Normalizar", value=True)
pca = st.sidebar.checkbox("Aplicar PCA", value=False)
pca_comp = st.sidebar.slider(
    "Componentes PCA",
    2,
    10,
    3,
    help="N√∫mero de componentes principais usados para reduzir dimensionalidade antes do clustering. S√≥ √© aplicado se 'Aplicar PCA' estiver marcado.",
    disabled=not pca
)

# ============================================================
# Par√¢metros de modelos (K, eps, etc.)
# ============================================================
st.sidebar.header("Par√¢metros de cluster")
k_clusters = st.sidebar.number_input(
    "N√∫mero de clusters (k) para k-means/hclust/birch/spectral (0 = auto)",
    min_value=0, value=0, step=1
)
dbscan_eps = st.sidebar.slider(
    "DBSCAN eps",
    min_value=0.05,
    max_value=5.0,
    value=1.0,
    step=0.05,
    help="Raio de vizinhan√ßa do DBSCAN. Aumente para formar menos clusters (mais aglomera√ß√£o); diminua para separar mais."
)
dbscan_min_samples = st.sidebar.number_input(
    "DBSCAN min_samples",
    min_value=1,
    value=5,
    step=1,
    help="N√∫mero m√≠nimo de pontos dentro de 'eps' para um ponto ser n√∫cleo. Aumente para clusters mais conservadores (mais ru√≠do)."
)
optics_min_samples = st.sidebar.number_input(
    "OPTICS min_samples",
    min_value=1,
    value=5,
    step=1,
    help="N√∫mero m√≠nimo de pontos para considerar um n√∫cleo no OPTICS. Controla a densidade m√≠nima dos clusters."
)

# Desempenho
st.sidebar.header("Desempenho")
limit_rows = st.sidebar.number_input(
    "Limitar amostras (0 = sem limite)",
    min_value=0,
    value=0,
    step=100,
    help="Subamostra a base para testes r√°pidos. 0 usa todos os registros; >0 sorteia exatamente esse n√∫mero de linhas."
)
models_to_try = st.sidebar.multiselect(
    "Algoritmos a testar",
    ["kmeans", "hclust", "dbscan", "optics", "birch", "spectral"],
    default=["kmeans", "hclust", "dbscan"]
)

# Extras visuais
st.sidebar.header("Exibi√ß√£o avan√ßada")
show_dendro_anyway = st.sidebar.checkbox("Mostrar dendrograma mesmo se n√£o for hclust", value=False)
heatmap_zscore = st.sidebar.checkbox("Heatmap com z-score (recomendado)", value=True)
heatmap_topn = st.sidebar.number_input("Heatmap: limitar √†s top-N vari√°veis (0 = todas)", min_value=0, value=0, step=1)

# ============================================================
# Aba EDA
# ============================================================
with eda_container:
    st.subheader("Vis√£o geral dos dados")
    st.write("Dimens√µes:", df.shape)
    st.dataframe(df.head())
    if (
        fonte != "Iris (Exemplo)"
        and "file" in locals()
        and file is not None
        and str(getattr(file, "name", "")).lower() == "country-data.csv"
    ):
        st.subheader("Entendimento do dataset")
        st.markdown(
            """
            | Coluna       | Descri√ß√£o                                           | Tipo       | Observa√ß√£o                             |
            | ------------ | --------------------------------------------------- | ---------- | ---------------------------------------|
            | `country`    | Nome do pa√≠s                                        | Categ√≥rica | Identificador (ignorado no clustering) |
            | `child_mort` | Taxa de mortalidade infantil (por 1000 nascimentos) | Num√©rica   | Importante indicador social            |
            | `exports`    | Exporta√ß√µes (% do PIB)                              | Num√©rica   | Econ√¥mico                              |
            | `health`     | Gastos com sa√∫de (% do PIB)                         | Num√©rica   | Econ√¥mico/Social                       |
            | `imports`    | Importa√ß√µes (% do PIB)                              | Num√©rica   | Econ√¥mico                              |
            | `income`     | Renda m√©dia per capita                              | Num√©rica   | Econ√¥mico                              |
            | `inflation`  | Taxa de infla√ß√£o (%)                                | Num√©rica   | Econ√¥mico                              |
            | `life_expec` | Expectativa de vida                                 | Num√©rica   | Social                                 |
            | `total_fer`  | Taxa de fertilidade                                 | Num√©rica   | Social                                 |
            | `gdpp`       | PIB per capita                                      | Num√©rica   | Econ√¥mico                              |
            """
        )
    if st.button("üîç Gerar relat√≥rio (profiling)", use_container_width=False):
        Profile = None
        try:
            from ydata_profiling import ProfileReport as Profile  # type: ignore
        except Exception:
            try:
                from pandas_profiling import ProfileReport as Profile  # type: ignore
            except Exception:
                Profile = None
        if Profile is None:
            st.info("Biblioteca de profiling n√£o instalada. Instale 'ydata-profiling' ou 'pandas-profiling' para ativar.")
        else:
            try:
                with st.spinner("Gerando relat√≥rio..."):
                    profile = Profile(df, title="Profiling ‚Äî Dataset", minimal=False)
                    html_str = profile.to_html()
                st.session_state.eda_profile_html = html_str
                st.success("Relat√≥rio gerado!")
            except Exception as e:
                st.error(f"Falha ao gerar o profiling: {e}")

    if st.session_state.get("eda_profile_html"):
        st.components.v1.html(st.session_state.eda_profile_html, height=900, scrolling=True)
        st.download_button(
            "üíæ Baixar relat√≥rio (HTML)",
            data=st.session_state.eda_profile_html.encode("utf-8"),
            file_name="profiling_relatorio.html",
            mime="text/html",
            use_container_width=False
        )
        if st.button("üóëÔ∏è Limpar Relat√≥rio", use_container_width=False, key="btn_clear_eda_report"):
            st.session_state.pop("eda_profile_html", None)
            st.rerun()

# ============================================================
# 4) Rodar Pipeline - Aba Treino & M√©tricas
# ============================================================
with treino_container:
    if st.button("Rodar Clusteriza√ß√£o"):
        data_full = safe_numeric_df(df, cols_num)
        if limit_rows and limit_rows > 0 and limit_rows < len(data_full):
            data = data_full.sample(n=limit_rows, random_state=42).reset_index(drop=True)
        else:
            data = data_full.copy()

        # Aplicar features a ignorar selecionadas pelo usu√°rio, considerando apenas as presentes nos dados do setup
        ignore_cols_effective = [c for c in cols_ignore if c in data.columns]

        setup(
            data=data,
            session_id=42,
            normalize=normalize,
            pca=pca,
            pca_components=pca_comp if pca else None,
            ignore_features=ignore_cols_effective,
            verbose=False,
            html=False,
        )

        st.success("Setup conclu√≠do")
        st.caption("Observa√ß√£o: colunas constantes foram removidas automaticamente antes do setup.")

        # Testar modelos
        resultados, objetos = [], {}
        k_models = {"kmeans", "hclust", "birch", "spectral"}

        for m in models_to_try:
            try:
                params = {}
                # aplica k se informado (>0) e se o modelo aceitar k
                if (k_clusters is not None) and (int(k_clusters) > 0) and (m in k_models):
                    params["num_clusters"] = int(k_clusters)
                # par√¢metros espec√≠ficos
                if m == "dbscan":
                    params["eps"] = float(dbscan_eps)
                    params["min_samples"] = int(dbscan_min_samples)
                if m == "optics":
                    params["min_samples"] = int(optics_min_samples)

                model = create_model(m, **params)
                labeled = assign_model(model, transformation=True)
                X = labeled.drop(columns=["Cluster"])
                y = labeled["Cluster"]

                sil, ch, db = compute_metrics(X, y)
                resultados.append([m, sil, ch, db])
                objetos[m] = (model, labeled)
            except Exception as e:
                resultados.append([m, np.nan, np.nan, np.nan])
                objetos[m] = (str(e), None)

        res_df = pd.DataFrame(resultados, columns=["Modelo", "Silhouette", "Calinski-Harabasz", "Davies-Bouldin"])
        # Persistir resultados para manter ap√≥s reruns
        st.session_state.cluster_results_df = res_df
        st.session_state.cluster_objects = objetos
        st.session_state.cluster_data_full = data_full
        st.session_state.cluster_data_sample = data
        st.session_state.cluster_df = df
        st.session_state.cluster_label_col = label_col
        st.session_state.cluster_setup_params = {
            "normalize": normalize,
            "pca": pca,
            "pca_components": pca_comp if pca else None,
            "ignore_features_user": cols_ignore,
            "ignore_features_effective": ignore_cols_effective,
        }

        st.success("Clusteriza√ß√£o conclu√≠da")
        st.rerun()

    # Renderiza√ß√£o persistente ap√≥s executar clusteriza√ß√£o
    if st.session_state.get("cluster_results_df") is not None:
        res_df = st.session_state.cluster_results_df
        objetos = st.session_state.cluster_objects
        data_full = st.session_state.cluster_data_full
        df = st.session_state.cluster_df
        label_col = st.session_state.cluster_label_col

        st.subheader("Compara√ß√£o de modelos")
        st.dataframe(res_df)

        # Interpreta√ß√£o autom√°tica
        st.subheader("Interpreta√ß√£o autom√°tica das m√©tricas")
        for _, row in res_df.iterrows():
            st.markdown(interpret_row(row["Modelo"], row["Silhouette"], row["Calinski-Harabasz"], row["Davies-Bouldin"]))

        # Escolher modelo
        st.subheader("An√°lise detalhada")
        escolha = st.selectbox("Modelo:", res_df["Modelo"].tolist(), key="cluster_model_select")
        obj, labeled_final = objetos.get(escolha, (None, None))

        if isinstance(obj, str) or labeled_final is None:
            st.warning(f"N√£o foi poss√≠vel analisar {escolha}")
            st.stop()

        st.write("Amostra com clusters atribu√≠dos:")
        st.dataframe(labeled_final.head())
        st.caption("Esta √© uma amostra para confer√™ncia r√°pida onde cada linha mostra um registro do dataset e a coluna ‚ÄòCluster‚Äô indica o grupo ao qual ele foi atribu√≠do.\n"
                   "Os demais n√∫meros s√£o valores padronizados:\n" 
                   "- 0 ‚âà m√©dia do conjunto;\n"
                   "- Valores positivos = acima da m√©dia;\n"
                   "- Valores negativos = abaixo da m√©dia.")

        # Perfis por cluster (tabela)
        st.subheader("Perfis dos clusters (estat√≠sticas)")
        prof = cluster_profiles_table(labeled_final, cluster_col="Cluster")
        if not prof.empty:
            st.dataframe(prof)
            st.caption("Resumo por grupo: para cada vari√°vel √© exibida a m√©dia, a mediana, a varia√ß√£o (desvio‚Äëpadr√£o) e os menores/maiores valores (m√≠n/m√°x) dentro do cluster. "
                       "Use para entender o que caracteriza cada grupo (ex.: ‚ÄòCluster 2 tem renda acima da m√©dia‚Äô). "
                       "Os valores est√£o padronizados, ent√£o compare sinais e magnitudes, n√£o unidades reais.")

        # Recriar contexto do PyCaret para permitir plot_model ap√≥s rerun
        try:
            _cfg = st.session_state.get("cluster_setup_params", {})
            _data_for_setup = st.session_state.get(
                "cluster_data_sample",
                labeled_final.drop(columns=["Cluster"], errors="ignore")
            )
            _user_ignore = _cfg.get("ignore_features_user", [])
            _ignore_features = [c for c in _user_ignore if hasattr(_data_for_setup, "columns") and c in _data_for_setup.columns]

            setup(
                data=_data_for_setup,
                session_id=42,
                normalize=_cfg.get("normalize", True),
                pca=_cfg.get("pca", False),
                pca_components=_cfg.get("pca_components"),
                ignore_features=_ignore_features,
                verbose=False,
                html=False,
            )
        except Exception:
            pass

        # Visualiza√ß√µes do modelo escolhido (PyCaret)
        st.subheader("Visualiza√ß√µes do modelo (PyCaret)")
        captions_map = {
            "elbow": "**Como ler:**\n"
                     "- Procure o ‚Äòcotovelo‚Äô: o ponto onde a curva deixa de cair r√°pido;\n"
                     "- O k nesse ponto costuma equilibrar simplicidade e qualidade do agrupamento;\n"
                     "- Se n√£o houver cotovelo claro, teste k pr√≥ximos e confirme com outras m√©tricas.",
            "silhouette": "**Como ler (vai de ‚àí1 a 1):**\n"
                          "- Quanto maior, melhor a separa√ß√£o (‚âà 0.5 ou mais √© bom);\n"
                          "- Pr√≥ximo de 0 indica mistura entre grupos (sobreposi√ß√£o);\n"
                          "- Negativo sugere pontos mal alocados;\n"
                          "- Barras longas acima de 0 para cada cluster indicam grupos coesos.",
            "tsne": "**Como ler:**\n"
                    "- Proje√ß√£o em 3D para visualizar proximidade entre amostras; os eixos n√£o t√™m significado direto.\n"
                    "- Grupos bem separados no gr√°fico sugerem clusters distintos e coesos; misturas/overlaps indicam fronteiras difusas.\n"
                    "- Pequenas varia√ß√µes entre execu√ß√µes s√£o normais (o t‚ÄëSNE √© estoc√°stico)."
        }
        for plot_type in ["elbow", "silhouette", "tsne"]:
            try:
                st.markdown(f"Plot: {plot_type}")
                plot_model(obj, plot=plot_type, display_format="streamlit")
                if plot_type in captions_map:
                    st.caption(captions_map[plot_type])
            except Exception as e:
                st.info(f"{plot_type} n√£o dispon√≠vel para {escolha}: {e}")

        # Dendrograma
        st.subheader("Dendrograma (hier√°rquico)")
        if escolha == "hclust" or show_dendro_anyway:
            X_for_dendro = labeled_final.drop(columns=["Cluster"])
            make_dendrogram(X_for_dendro, sample_cap=250, method="ward")
            st.caption("**Como ler:**\n"
                       "- Cada ‚Äòuni√£o‚Äô representa mesclagem de grupos parecidos;\n"
                       "- A altura da uni√£o mostra o qu√£o diferentes eles eram (quanto maior, mais diferentes);\n"
                       "- ‚ÄòSaltos‚Äô grandes de altura sugerem fronteiras naturais entre clusters (corte horizontal pouco antes do salto).")
        else:
            st.info("Dendrograma √© mais apropriado para hclust. Ative a op√ß√£o na barra lateral para for√ßar exibi√ß√£o.")

        # Heatmap das m√©dias
        st.subheader("Heatmap das m√©dias por cluster")
        top_n = int(heatmap_topn) if heatmap_topn and heatmap_topn > 0 else None
        plot_cluster_means_heatmap(labeled_final, cluster_col="Cluster",
                                   zscore=heatmap_zscore, top_n_features=top_n)
        st.caption("**Como ler:**\n"
                   "- Cada c√©lula mostra a m√©dia da vari√°vel no cluster (z‚Äëscore se ativado);\n"
                   "- Cores positivas = valores acima da m√©dia global;\n"
                   "- Cores negativas = valores abaixo da m√©dia global.\n"
                   "- Compare colunas para ver quais vari√°veis diferenciam os clusters e linhas para entender o ‚Äòperfil‚Äô de cada grupo.")

        # Compara√ß√£o com r√≥tulos verdadeiros (opcional)
        if ('label_col' in locals()) and label_col and label_col in df.columns:
            st.subheader("Compara√ß√£o clusters √ó r√≥tulos")
            if limit_rows and limit_rows > 0 and limit_rows < len(data_full):
                sampled_idx = data_full.sample(n=limit_rows, random_state=42).index
                truth_series = df.loc[sampled_idx, label_col].reset_index(drop=True)
            else:
                truth_series = df[label_col].reset_index(drop=True)

            if len(truth_series) == len(labeled_final):
                labeled_cmp = labeled_final.copy()
                labeled_cmp[label_col] = truth_series
                ctab = pd.crosstab(labeled_cmp["Cluster"], labeled_cmp[label_col])
                st.dataframe(ctab)
                mapping, purity = best_cluster_label_mapping(labeled_cmp, cluster_col="Cluster", truth_col=label_col)
                st.write("Mapeamento cluster ‚Üí r√≥tulo mais frequente:")
                st.json(mapping)
                st.write(f"Pureza global: {purity:.3f}")
            else:
                st.info("N√£o foi poss√≠vel alinhar r√≥tulos com a amostra usada no clustering.")

        # Downloads
        st.subheader("Downloads")
        st.download_button("Baixar clusters (CSV)", labeled_final.to_csv(index=False).encode("utf-8"), "clusters.csv")
        os.makedirs(os.path.join("results", "models"), exist_ok=True)
        save_model(obj, os.path.join("results", "models", "modelo_cluster"))
        with open(os.path.join("results", "models", "modelo_cluster.pkl"), "rb") as f:
            st.download_button("Baixar modelo (PKL)", f, "modelo_cluster.pkl")

# ============================================================
# Aba Relat√≥rio
# ============================================================
with relatorio_container:
    # ============================
    # RELAT√ìRIO DE RESULTADOS
    # ============================

    st.header("Relat√≥rio de Resultados da Clusteriza√ß√£o")

    st.markdown("""
    Ap√≥s a execu√ß√£o do processo de clusteriza√ß√£o, o modelo **K-Means** foi identificado como o mais adequado
    para o dataset `Country-data.csv`, com base nas m√©tricas internas obtidas:

    - **Silhouette ‚âà 0.29** ‚Üí separa√ß√£o moderada entre clusters (estrutura existente, mas com sobreposi√ß√£o leve);
    - **Calinski‚ÄìHarabasz ‚âà 54.4** ‚Üí boa compacta√ß√£o e separa√ß√£o interna;
    - **Davies‚ÄìBouldin ‚âà 1.0** ‚Üí separa√ß√£o aceit√°vel entre grupos.

    Esses valores indicam que o K-Means conseguiu capturar **padr√µes socioecon√¥micos distintos entre os pa√≠ses**,
    apesar de transi√ß√µes graduais entre alguns grupos ‚Äî o que √© esperado em dados de desenvolvimento humano e econ√¥mico.
    """)

    # Recuperar dataset rotulado
    if "labeled_final" in locals() or "labeled_final" in globals():
        labeled = labeled_final.copy()
    else:
        st.warning("Nenhum modelo executado ainda. Execute a clusteriza√ß√£o antes de gerar o relat√≥rio.")
        st.stop()

    # ---------------------------
    # Interpreta√ß√£o geral
    # ---------------------------
    st.subheader("Interpreta√ß√£o Geral dos Clusters")

    st.markdown("""
    O modelo K-Means formou **4 clusters principais**, representando diferentes est√°gios de desenvolvimento econ√¥mico e social:

    | Cluster  | Descri√ß√£o  | Caracter√≠sticas predominantes |
    |----------|------------|-------------------------------|
    | **0** | Pa√≠ses em desenvolvimento intermedi√°rio | PIB e renda modestos, mortalidade infantil ainda alta, fertilidade elevada, expectativa de vida m√©dia. |
    | **1** | Pa√≠ses desenvolvidos                    | Alta renda e PIB per capita, elevada expectativa de vida, baixa mortalidade e fertilidade, infla√ß√£o controlada, forte abertura comercial. |
    | **2** | Pa√≠ses de baixo desenvolvimento         | Renda e PIB baixos, mortalidade e fertilidade altas, expectativa de vida reduzida, infla√ß√£o relativamente alta. |
    | **3** | Pa√≠s isolado de vulnerabilidade extrema (Nig√©ria) | Mortalidade e fertilidade extremamente altas, renda e expectativa de vida muito baixas, infla√ß√£o muito elevada. |

    Esses agrupamentos refletem uma **progress√£o socioecon√¥mica coerente**, indo de pa√≠ses de **vulnerabilidade extrema (Cluster 3)**
    at√© **economias desenvolvidas (Cluster 1)**, com **est√°gios intermedi√°rios (Clusters 0 e 2)**.
    """)

    # Preparar dataset exib√≠vel
    labeled_display = labeled.copy()
    if 'country' not in labeled_display.columns:
        df_full = st.session_state.get("cluster_df")
        if df_full is not None and 'country' in df_full.columns:
            labeled_display['country'] = df_full['country']
    # M√©tricas de tamanho/outliers para uso posterior
    cluster_counts = labeled_display['Cluster'].value_counts()
    isolated_clusters = cluster_counts[cluster_counts == 1].index.tolist()

    # ---------------------------
    # Mapa 2D via PCA
    # ---------------------------
    st.subheader("Visualiza√ß√£o 2D dos Clusters (PCA)")

    st.markdown("""
    O Principal Component Analysis (PCA) √© utilizado para resumir todas as vari√°veis em dois eixos (componentes PC1 e PC2) para visualiza√ß√£o, sendo que, neste caso, cada ponto na imagem representa um pa√≠s.  
    - Pontos **pr√≥ximos** indicam pa√≠ses com perfis socioecon√¥micos semelhantes.  
    - Pontos **distantes** indicam perfis distintos.  
    - As **cores** correspondem aos clusters identificados.
    """)

    from sklearn.decomposition import PCA
    import plotly.express as px

    cols_num = [c for c in labeled_display.columns if c not in ['country', 'Cluster']]
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(labeled_display[cols_num])
    df_pca = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])
    df_pca['Cluster'] = labeled_display['Cluster']
    df_pca['country'] = labeled_display['country']

    # Ordem fixa dos clusters para manter consist√™ncia de cores
    cluster_order = sorted(df_pca['Cluster'].unique())

    fig_pca = px.scatter(
        df_pca, x='PC1', y='PC2',
        color='Cluster', hover_name='country',
        title='Mapa Socioecon√¥mico 2D (PCA)',
        category_orders={'Cluster': cluster_order},
    )
    st.plotly_chart(fig_pca, use_container_width=True)

    st.caption("""
    **Leitura do gr√°fico:**
    - *Cluster 1* (desenvolvidos) forma um grupo compacto e distante, com indicadores homog√™neos e altos n√≠veis de renda e qualidade de vida.  
    - *Cluster 0* aparece como faixa intermedi√°ria de desenvolvimento.  
    - *Cluster 2* agrupa pa√≠ses de baixo desenvolvimento, com indicadores desfavor√°veis.  
    - *Cluster 3* (Nig√©ria) surge isolado ‚Äî reflexo de um perfil socioecon√¥mico extremamente desfavor√°vel.
    """)

    # ---------------------------
    # Mapa Mundial
    # ---------------------------
    st.subheader("Distribui√ß√£o Geogr√°fica dos Clusters")

    st.markdown("""
    O mapa abaixo mostra a distribui√ß√£o dos clusters por pa√≠s.  
    Cores semelhantes indicam pa√≠ses com caracter√≠sticas socioecon√¥micas pr√≥ximas.
    """)

    # Preparar mapa de cores do PCA para reutilizar em outras se√ß√µes
    pca_color_map = {}
    try:
        for tr in getattr(fig_pca, 'data', []):
            cat_name = str(tr.name)
            tr_color = getattr(tr.marker, 'color', None)
            if isinstance(tr_color, (list, tuple)) and tr_color:
                tr_color = tr_color[0]
            pca_color_map[cat_name] = tr_color

        df_map = labeled_display.copy()
        df_map['ClusterLabel'] = df_map['Cluster'].apply(lambda c: str(c))
        fig_map = px.choropleth(
            df_map,
            locations="country",
            locationmode="country names",
            color="ClusterLabel",
            title="Mapa Mundial por Cluster (Country-data)",
            category_orders={'ClusterLabel': [str(c) for c in cluster_order]},
            color_discrete_map=pca_color_map,
            labels={'ClusterLabel': 'Cluster'},
        )
        fig_map.update_layout(legend_title_text='Cluster')
        st.plotly_chart(fig_map, use_container_width=True)
    except Exception as e:
        st.warning("N√£o foi poss√≠vel gerar o mapa geogr√°fico. Verifique se os nomes dos pa√≠ses est√£o padronizados.")

    # ---------------------------
    # Tamanho dos clusters e outliers
    # ---------------------------
    st.subheader("Tamanho dos Clusters e Outliers")
    st.markdown("""
    O gr√°fico (doughnut) abaixo apresenta a quantidade de pa√≠ses distribu√≠dos por cluster.  
    Cada setor representa a propor√ß√£o de pa√≠ses em cada grupo.
    """)
    try:
        counts_df = cluster_counts.sort_index().rename_axis('Cluster').reset_index(name='Quantidade')
        counts_df['ClusterStr'] = counts_df['Cluster'].astype(str)
        fig_counts = px.pie(
            counts_df,
            names='ClusterStr',
            values='Quantidade',
            color='ClusterStr',
            category_orders={'ClusterStr': [str(c) for c in cluster_order]},
            color_discrete_map=pca_color_map,
            title='Participa√ß√£o de Pa√≠ses por Cluster',
            hole=0.5
        )
        fig_counts.update_layout(legend_title_text='Cluster')
        st.plotly_chart(fig_counts, use_container_width=True)
    except Exception:
        st.table(cluster_counts.sort_index())

    if isolated_clusters:
        st.markdown("### ‚ö†Ô∏è Cluster(s) Isolado(s) Detectado(s)")
        for c in isolated_clusters:
            isolated_country = labeled_display.loc[labeled_display['Cluster'] == c, 'country'].values[0]
            label = str(c)
            if not label.lower().startswith("cluster"):
                label = f"Cluster {label}"
            st.info(f"**{label}** cont√©m apenas **{isolated_country}**, indicando um poss√≠vel outlier com perfil socioecon√¥mico extremo.")
        st.caption("""
        **Interpreta√ß√£o:**  
        O modelo detectou pa√≠s(es) significativamente diferentes dos demais.  
        No caso atual, a **Nig√©ria** apresenta mortalidade infantil, fertilidade e infla√ß√£o muito elevadas,
        al√©m de baixa renda e expectativa de vida, justificando seu isolamento.
        """)

    # ---------------------------
    # Perfil socioecon√¥mico m√©dio
    # ---------------------------
    st.subheader("Perfil Socioecon√¥mico M√©dio por Cluster")

    st.markdown("""
    O gr√°fico abaixo apresenta as m√©dias normalizadas das vari√°veis socioecon√¥micas dentro de cada grupo.
    Valores positivos indicam m√©dias **acima da m√©dia global** e negativos, **abaixo da m√©dia global**.
    """)

    import plotly.graph_objects as go

    mean_by_cluster = labeled_display.groupby('Cluster')[cols_num].mean()

    fig_profile = go.Figure()
    for c in mean_by_cluster.index:
        fig_profile.add_trace(go.Bar(
            x=mean_by_cluster.columns,
            y=mean_by_cluster.loc[c],
            name=str(c),
        ))
    fig_profile.update_layout(
        barmode='group',
        title='Perfil Socioecon√¥mico M√©dio (valores normalizados)',
        xaxis_title='Vari√°veis',
        yaxis_title='M√©dia normalizada',
        height=500,
        legend_title_text='Cluster',
    )
    st.plotly_chart(fig_profile, use_container_width=True)

    st.caption("""
    **Interpreta√ß√£o:**
    - *Cluster 1* (**desenvolvidos**): maiores valores em **income**, **gdpp**, **health**, **life_expec**, **exports** e **imports**; menores em **child_mort**, **total_fer** e **inflation**.  
    - *Cluster 0*: indicadores m√©dios, representando pa√≠ses em **desenvolvimento intermedi√°rio**.  
    - *Cluster 2* (**baixo desenvolvimento**): renda e PIB baixos e mortalidade/fertilidade elevadas.  
    - *Cluster 3* (**Nig√©ria**): perfil extremo ‚Äî infla√ß√£o e mortalidade muito altas, renda e expectativa de vida muito baixas.
    """)

    # ---------------------------
    # Distribui√ß√£o por vari√°vel (oculta)
    # ---------------------------
    with st.expander("Distribui√ß√£o por vari√°vel"):
        st.markdown("""
        Nesta se√ß√£o s√£o exibidos gr√°ficos do tipo **boxplot** para cada vari√°vel selecionada, separados por cluster.
        O objetivo √© comparar a **distribui√ß√£o** das vari√°veis entre os grupos.
        
        Como interpretar:
        - **Linha central**: a mediana dos valores do cluster;
        - **Caixa**: intervalo interquartil (Q1‚ÄìQ3), onde se concentram 50% dos valores;
        - **Bigodes**: varia√ß√£o t√≠pica (sem outliers) dos dados;
        - **Pontos fora da caixa**: poss√≠veis outliers.
        
        Selecione abaixo as vari√°veis para explorar suas distribui√ß√µes por cluster.
        """)
        candidate_vars = [v for v in cols_num if v in ['income','gdpp','life_expec','child_mort','total_fer','inflation','health','imports','exports']]
        default_vars = [v for v in ['health','gdpp','life_expec','child_mort'] if v in candidate_vars]
        selected_vars = st.multiselect("Selecione as vari√°veis para visualizar:", options=candidate_vars, default=default_vars)
        for var in selected_vars:
            df_box = labeled_display[['Cluster', var]].copy()
            df_box['ClusterStr'] = df_box['Cluster'].astype(str)
            fig_box = px.box(
                df_box, x='ClusterStr', y=var, color='ClusterStr',
                category_orders={'ClusterStr': [str(c) for c in cluster_order]},
                color_discrete_map=pca_color_map,
                points='outliers',
                title=f'Distribui√ß√£o de {var} por Cluster'
            )
            fig_box.update_layout(xaxis_title='Cluster', legend_title_text='Cluster')
            st.plotly_chart(fig_box, use_container_width=True)

    # ---------------------------
    # Tabela de pa√≠ses e clusters
    # ---------------------------
    st.subheader("Pa√≠ses e seus Clusters")
    st.markdown("""
    A tabela abaixo mostra cada pa√≠s e o grupo (cluster) ao qual foi atribu√≠do.
    Os pa√≠ses est√£o ordenados por cluster para facilitar a interpreta√ß√£o dos agrupamentos.
    """)
    st.dataframe(
        labeled_display[['country', 'Cluster']].sort_values(by='Cluster'),
        use_container_width=True,
    )

    # ---------------------------
    # Conclus√µes
    # ---------------------------
    st.subheader("Conclus√µes e Pr√≥ximos Passos")

    st.markdown("""
    **Resumo da an√°lise:**
    - O **modelo K-Means (k = 4)** capturou uma estrutura coerente de desenvolvimento socioecon√¥mico global.  
    - *Cluster 1* agrupa pa√≠ses **desenvolvidos**; *Cluster 0* representa pa√≠ses em est√°gio **intermedi√°rio**; *Cluster 2* re√∫ne **pa√≠ses de baixo desenvolvimento**; *Cluster 3* (**Nig√©ria**) destaca-se como caso isolado e cr√≠tico.  
    - Os resultados refor√ßam a coer√™ncia entre os indicadores econ√¥micos e sociais.

    **Sugest√µes de continuidade:**
    1. Testar valores alternativos de *k* para avaliar estabilidade dos grupos.  
    2. Aplicar transforma√ß√£o de pot√™ncia (`transformation=True`) para suavizar outliers.  
    3. Incluir vari√°veis adicionais (educa√ß√£o, IDH, desigualdade, urbaniza√ß√£o).  
    4. Avaliar evolu√ß√£o temporal para estudar mudan√ßas nos clusters ao longo dos anos.  

    Essas an√°lises complementares podem refor√ßar o entendimento das diferen√ßas estruturais entre os pa√≠ses
    e apoiar pol√≠ticas p√∫blicas e estrat√©gias de desenvolvimento mais direcionadas.
    """)
